% !TEX root = ../main.tex
% The abstract.
% Included by MAIN.TEX
\clearemptydoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Abstract}

\vspace*{2cm}
\begin{center}
{\Large \textbf{Abstract}}
\end{center}
\vspace{1cm}

\chapter*{Abstract}
\label{chapter:Abstract}

\ac{rl} has shown remarkable progress in recent years, but still faces challenges in solving tasks with high-dimensional 
continuous state and action spaces, and sparse rewards. This thesis proposes a new \ac{rl} paradigm called \ac{avc}, which uses search at 
inference time and leverages expert demonstrations to overcome these challenges. \ac{avc} is a general-purpose algorithm applicable to both deterministic 
\ac{mdp}s and deterministic \ac{pomdp}s, and is the first algorithm to use inference-time search on continuous 
action spaces without a given model of the environment.\\

In this thesis, we investigate the effectiveness of \ac{avc} in solving tasks with sparse rewards and limited observations. We test \ac{avc} on 
a setup where a single observation per trajectory is provided along with expert demonstrations, as well as on an \ac{mdp} setting with observations 
after each step. We compare AC's performance to state-of-the-art \ac{rl} algorithms, TQC and PPO, as well as to GAIL, a state-of-the-art imitation 
learning algorithm. \\

Our experimental results show that \ac{avc} outperforms the selected baselines in both the single observation \ac{pomdp}s and MDPs, achieving superior 
performance while maintaining high sample efficiency. We also propose several avenues for future research, such as incorporating stochastic 
observations, modelling uncertainty estimates, and incorporating curiosity-driven exploration.\\

Overall, the results demonstrate the efficacy of the \ac{avc} paradigm in leveraging expert knowledge and search to achieve swift learning and 
increased stability in challenging \ac{rl} tasks.