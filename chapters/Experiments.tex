% !TEX root = ../main.tex

\chapter{Experiments}
\label{chapter:Experiments}
The goal of our experimental evaluation is to understand how the two main ideas of our algorithm contribute to its perforance in one observation, obscure goal 
POMDPs, namely the weak inductive bias as developed in \ref{COD_AC} and the inference time planning developed in \ref{inference_time_planning}. 
To do this, we first analyze our weak inductive bias against a proposed method using a recurrent architecture. 
We directly compare our results on the benchmark they provided. Second, we evaluate the perforance difference between pure imitation learning and reinforcement 
learning with expert demonstrations on the reach environment from the Meta-World benchmark. Here we compare our inference time planning against two state of 
the arts reinforcement learning algorithms, which are pretrained using behavioural cloning. For our third experiment setup, we evaluate our approach against 
baselines on 5 tasks from the Meta-World benchmark. As one observation POMDPs are not well studied, we propose a variety of  
baselines aiming to challenge aspects we developed in our methodology.
